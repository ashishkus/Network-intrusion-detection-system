{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>\"protocol_type\"</th>\n",
       "      <th>\"service\"</th>\n",
       "      <th>flag</th>\n",
       "      <th>\"src_bytes\"</th>\n",
       "      <th>\"dst_bytes\"</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>\"hot\"</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate.1</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>S1</td>\n",
       "      <td>278</td>\n",
       "      <td>7958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>241</td>\n",
       "      <td>851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>239</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>367</td>\n",
       "      <td>5199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21263</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>probe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  \"protocol_type\" \"service\"  flag  \"src_bytes\"   \"dst_bytes\"  land  \\\n",
       "0         0              tcp      http    S1          278          7958     0   \n",
       "1         0              tcp      http    SF          241           851     0   \n",
       "2         0              udp   private    SF          105           146     0   \n",
       "3         0              tcp      http    SF          367          5199     0   \n",
       "4     21263              tcp   private  RSTR            1             0     0   \n",
       "\n",
       "    wrong_fragment  urgent   \"hot\"  ...  dst_host_srv_count  \\\n",
       "0                0       0       0  ...                 255   \n",
       "1                0       0       0  ...                 255   \n",
       "2                0       0       0  ...                 239   \n",
       "3                0       0       0  ...                 255   \n",
       "4                0       0       0  ...                   2   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  dst_host_diff_srv_rate.1  \\\n",
       "0                    1.00                    0.00                      0.33   \n",
       "1                    1.00                    0.00                      0.01   \n",
       "2                    0.94                    0.01                      0.01   \n",
       "3                    1.00                    0.00                      0.01   \n",
       "4                    0.01                    0.66                      1.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.03                  0.33   \n",
       "1                         0.03                  0.00   \n",
       "2                         0.00                  0.00   \n",
       "3                         0.05                  0.00   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                   0.0                       0.0   \n",
       "1                       0.0                   0.0                       0.0   \n",
       "2                       0.0                   0.0                       0.0   \n",
       "3                       0.0                   0.0                       0.0   \n",
       "4                       0.0                   1.0                       1.0   \n",
       "\n",
       "    label  \n",
       "0  normal  \n",
       "1  normal  \n",
       "2  normal  \n",
       "3  normal  \n",
       "4   probe  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = pd.read_csv('C:/Users/Aditya Kyatham/Documents/BE FINAL/nsl-kdd/NSL_KDD-master/Small Training Set_5class_train.csv', index_col=None)\n",
    "testdata = pd.read_csv('C:/Users/Aditya Kyatham/Documents/BE FINAL/nsl-kdd/NSL_KDD-master/Small Training Set_5class_test.csv', index_col=None)\n",
    "\n",
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encodings = dict()\n",
    "for c in traindata.columns:\n",
    "    #print df[c].dtype\n",
    "    if traindata[c].dtype == \"object\":\n",
    "        encodings[c] = LabelEncoder() #to give numerical label to char type labels.\n",
    "        encodings[c]\n",
    "        traindata[c] = encodings[c].fit_transform(traindata[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings1 = dict()\n",
    "for c in testdata.columns:\n",
    "    #print df[c].dtype\n",
    "    if testdata[c].dtype == \"object\":\n",
    "        encodings1[c] = LabelEncoder() #to give numerical label to char type labels.\n",
    "        encodings1[c]\n",
    "        testdata[c] = encodings1[c].fit_transform(testdata[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindata.iloc[:,0:41]\n",
    "Y = traindata.iloc[:,41]\n",
    "C = testdata.iloc[:,41]\n",
    "T = testdata.iloc[:,0:41]\n",
    "\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 0.141 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "              learning_rate='optimal', loss='squared_hinge', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3,loss='squared_hinge',alpha = 1)\n",
    "t0 = time()\n",
    "clf.fit(traindata,trainlabel)\n",
    "tt = time() - t0\n",
    "print (\"Classifier trained in {} seconds.\".format(round(tt, 3)))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted in 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predictions on the test data\n",
    "t0 = time()\n",
    "pred = clf.predict(testdata)\n",
    "tt = time() - t0\n",
    "print (\"Predicted in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[63  1  0  0  0]\n",
      " [ 9 99  0  0  0]\n",
      " [15 11  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  3  0  0  0]]\n",
      "Accuracy Score : 0.7980295566502463\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        64\n",
      "           1       0.85      0.92      0.88       108\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.80       203\n",
      "   macro avg       0.32      0.38      0.34       203\n",
      "weighted avg       0.68      0.80      0.73       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Kyatham\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    " \n",
    "results = confusion_matrix(testlabel, pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(testlabel, pred))\n",
    "print('Report : ')\n",
    "print(classification_report(testlabel, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Kyatham\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Aditya Kyatham\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8353960396039604\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       316\n",
      "           1       0.83      0.94      0.88       408\n",
      "           2       0.00      0.00      0.00        65\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.84       808\n",
      "   macro avg       0.33      0.37      0.35       808\n",
      "weighted avg       0.75      0.84      0.79       808\n",
      "\n",
      "Predicted in 0.294 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "predicted = cross_val_predict(clf, traindata,trainlabel, cv=skf)\n",
    "print('Accuracy Score :',accuracy_score(trainlabel, predicted))\n",
    "print('Report : ')\n",
    "print(classification_report(trainlabel, predicted))\n",
    "tt = time() - t0\n",
    "print (\"Predicted in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StratifiedKFold' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a0a1f79b4848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predictions on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted in {} seconds\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StratifiedKFold' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#Predictions on the test data\n",
    "t0 = time()\n",
    "pred = skf.predict(testdata)\n",
    "tt = time() - t0\n",
    "print (\"Predicted in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[63  1  0  0  0]\n",
      " [ 9 99  0  0  0]\n",
      " [15 11  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  3  0  0  0]]\n",
      "Accuracy Score : 0.7980295566502463\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        64\n",
      "           1       0.85      0.92      0.88       108\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.80       203\n",
      "   macro avg       0.32      0.38      0.34       203\n",
      "weighted avg       0.68      0.80      0.73       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Kyatham\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    " \n",
    "results = confusion_matrix(testlabel, pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(testlabel, pred))\n",
    "print('Report : ')\n",
    "print(classification_report(testlabel, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
